#portfolio
#install.packages('readr')
library(readr)
temp = list.files(pattern="*.csv")
myfiles = lapply(temp, read.csv)
names = c("")

# list all csv files from the current directory
list.files(pattern=".csv$") # use the pattern argument to define a common pattern  for import files with regex. Here: .csv

# create a list from these files
list.filenames<-list.files(pattern=".csv$")
list.filenames

# create an empty list that will serve as a container to receive the incoming files
list.data<-list()

# create a loop to read in your data
for (i in 1:length(list.filenames))
{
  list.data[[i]]<-read.csv(list.filenames[i])
}

# add the names of your data to the list
names(list.data)<-list.filenames
da <- list.data
bat = data.frame(da[1])
btc = data.frame(da[2])
dash = data.frame(da[3])
#eos = data.frame(da[4])
eth = data.frame(da[5])
iota = data.frame(da[6])
lsk = data.frame(da[7])
ltc = data.frame(da[8])
maid = data.frame(da[9])
neo = data.frame(da[10])
xem = data.frame(da[11])
xmr = data.frame(da[12])
xrp = data.frame(da[13])
zec = data.frame(da[14])


#close_prices = data.frame(lapply(da, '[[', 3))    

bat = bat[ , 2:5]
btc = btc[ , 2:5]
dash = dash[ , 2:5]
#eos = eos[ , 1:2]
eth = eth[ , 2:5]
iota = iota[ , 2:5]
lsk = lsk[ , 2:5]
ltc = ltc[ , 2:5]
neo = neo[ , 2:5]
xem = xem[ , 2:5]
xmr = xmr[ , 2:5]
xrp = xrp[ , 2:5]
zec = zec[ , 2:5]
maid = maid[ , 2:5]


bat$volatility = bat[,3] - bat[,4]
btc$volatility = btc[,3] - btc[,4]
dash$volatility = dash[,3] - dash[,4]
#we cannot use eos because there is no data about its volatility (high -low)
eth$volatility = eth[,3] - eth[,4]
iota$volatility = iota[,3] - iota[,4]
lsk$volatility = lsk[,3] - lsk[,4]
ltc$volatility = ltc[,3] - ltc[,4]
neo$volatility = neo[,3] - neo[,4]
xem$volatility = xem[,3] - xem[,4]
xmr$volatility = xmr[,3] - xmr[,4]
xrp$volatility = xrp[,3] - xrp[,4]
zec$volatility = zec[,3] - zec[,4]
maid$volatility = maid[,3] - maid[,4]

#for different reasons, we will not use nor eos nor bat; the first one because it is still on ICO and most importantly there is no data for USD High and USD Low daily.
#for BAT we do not have sufficient data...

#the one with less data is neo, with 197 observations. Therefore, we should take the last 191 observations of all coins
n = 196

btc = btc[(nrow(btc)-n):nrow(btc),]
dash = dash[(nrow(dash)-n):nrow(dash),]
eth = eth[(nrow(eth)-n):nrow(eth),]
iota = iota[(nrow(iota)-n):nrow(iota),]
lsk = lsk[(nrow(lsk)-n):nrow(lsk),]
ltc = ltc[(nrow(ltc)-n):nrow(ltc),]
xem = xem[(nrow(xem)-n):nrow(xem),]
xmr = xmr[(nrow(xmr)-n):nrow(xmr),]
xrp = xrp[(nrow(xrp)-n):nrow(xrp),]
zec = zec[(nrow(zec)-n):nrow(zec),]
maid = maid[(nrow(maid)-n):nrow(maid),]

btc$ret = c(NA, diff(log(btc$btc.csv.close)))
dash$ret = c(NA, diff(log(dash$dash.csv.close)))
eth$ret = c(NA, diff(log(eth$eth.csv.close)))
iota$ret = c(NA, diff(log(iota$iot.csv.close)))
lsk$ret = c(NA, diff(log(lsk$lsk.csv.close)))
ltc$ret = c(NA, diff(log(ltc$ltc.csv.close)))
neo$ret = c(NA, diff(log(neo$neo.csv.close)))
xem$ret = c(NA, diff(log(xem$xem.csv.close)))
xmr$ret = c(NA, diff(log(xmr$xmr.csv.close)))
xrp$ret = c(NA, diff(log(xrp$xrp.csv.close)))
zec$ret = c(NA, diff(log(zec$zec.csv.close)))
maid$ret = c(NA, diff(log(maid$maid.csv.close)))

btc = btc[2:nrow(btc), ]
eth = eth[2:nrow(eth), ]
dash = dash[2:197, ]
iota = iota[2:197, ]
lsk = lsk[2:197, ]
ltc = ltc[2:197, ]
neo = neo[2:197, ]
xem = xem[2:197, ]
xmr = xmr[2:197, ]
xrp = xrp[2:197, ]
zec = zec[2:197, ]
maid = maid[2:197, ]

returns = cbind(btc$ret, eth$ret, dash$ret, iota$ret, lsk$ret, neo$ret, xem$ret, xmr$ret, xrp$ret, zec$ret, maid$ret)
returns = data.frame(returns)
colnames(returns) = c("btc", "eth", "dash", "iota", "lsk", "neo", "xem", "xmr", "xrp", "zec", "maid")

cor_mat = cor(returns)

#install.packages("corrplot")
library(corrplot)
corrplot(cor_mat, method='shade', type='full', shade.col=NA, tl.col='black')



#install.packages("TSclust")
library(TSclust)
D1 <- diss(returns, "COR")
summary(D1)

average_return_btc = mean(btc$ret)

#install.packages("dplyr")
library(dplyr)
summary_ret = returns %>% 
  summarize(av_ret_btc = mean(btc),
            av_ret_eth = mean(eth), 
            av_ret_dash = mean(dash), 
            av_ret_iota = mean(iota),
            av_ret_lsk = mean(lsk), 
            av_ret_neo = mean(neo),
            av_ret_xem = mean(xem), 
            av_ret_xmr = mean(xmr), 
            av_ret_xrp = mean(xrp), 
            av_ret_zec = mean(zec), 
            av_ret_maid = mean(maid))
#here we see the average return for the period selected of the cryptocurrencies under consideration. 

C1 <- hclust(D1)
C1
plot(C1)

D2 <- diss(returns, "FRECHET")

c2 = hclust(D2)
c2
plot(c2)

#it seems that cluster analysis (at least hierarchical one) does not provide much information. 
#we are going to try more methods
d3 <- diss(returns, "ACF")

c3 = hclust(d3)
c3
plot(c3)

#install.packages("ggdendro")
library(ggplot2)
library(ggdendro)

ggdendrogram(c3, rotate = FALSE, theme_dendro = FALSE, segments = TRUE, labels = TRUE )  +
  ggtitle('                        HIERARCHICAL CLUSTER OF CRYPTOCURRENCIES      ')


#the next step is to create tables for each category of cryptocurrencies, and put some variables 

total_perc_ret_btc = (btc$btc.csv.close[nrow(btc)] - btc$btc.csv.close[1])/btc$btc.csv.close[1]
print(total_perc_ret_btc)
total_perc_ret_eth = (eth$eth.csv.close[nrow(eth)] - eth$eth.csv.close[1])/eth$eth.csv.close[1]
print(total_perc_ret_eth)

mean_daily_vol_btc = mean(btc$volatility)
print(mean_daily_vol_btc)
mean_daily_vol_eth = mean(eth$volatility)
print(mean_daily_vol_eth) #much lower volatility

mean_price_btc = mean(btc$btc.csv.close)
mean_vol_to_mean_price_btc = mean_daily_vol_btc/mean_price_btc

mean_price_eth = mean(eth$eth.csv.close)
mean_vol_to_mean_price_eth = mean_daily_vol_eth/mean_price_eth

mean_daily_ret_btc = mean(btc$ret)
mean_daily_ret_eth = mean(eth$ret)

mean_daily_perc_vol_btc = mean(btc$volatility) / mean(btc$btc.csv.close)
mean_daily_perc_vol_eth = mean(eth$volatility) / mean(eth$eth.csv.close)


#we now need to take into account the google interest towards the cryptocurrencies

library(readr)
interest = read_csv('eth_btc_google.csv')
interest = data.frame(interest)
interest$btc = interest$btc/100
interest$eth = interest$eth/100
interest$date = as.Date(interest$date)

library(ggplot2)

btc_eth_int <- ggplot(data = interest, aes(x = date)) +
  geom_line(aes(y = btc, linetype = "btc")) +
  geom_line(aes(y = eth, linetype = "eth")) +
  ggtitle('                     Interest on btc and eth      ') +
  scale_linetype_discrete(name ="")
btc_eth_int

avg_interest_btc = mean(interest$btc)
avg_interest_eth = mean(interest$eth)



btc2 = read_csv('btc.csv')
nrow(btc2) #this number of observations is going to be used for taking the inverse of the time, so that we give more weight to currencies that have had good performancce but are not still in the maturity stage, not even close (btc is also not in the maturity stage, but we expect ethereum to have more relevance in the coming years, as in less time it has done as much as bitcoin for the cryptocurrency community, if not more)
inv_time_btc = 1 / (nrow(btc2) / 365) #0.1316264

eth2 = read_csv('eth.csv')
nrow(eth2)
inv_time_eth = 1 / (nrow(eth2) / 365) #0.3941685

#let's visualize the movement of the returns of both series
ggplot(data = returns, aes(x = seq(1, nrow(returns), 1))) +
  geom_line(aes(y = btc, linetype = "btc")) +
  geom_line(aes(y = eth, linetype = "eth")) +
  ggtitle('                                btc and eth returns') +
  scale_linetype_discrete(name = "")


#anonymity cryptos
total_perc_ret_xmr = (xmr$xmr.csv.close[nrow(xmr)] - xmr$xmr.csv.close[1])/xmr$xmr.csv.close[1]
total_perc_ret_zec = (zec$zec.csv.close[nrow(zec)] - zec$zec.csv.close[1])/zec$zec.csv.close[1]
total_perc_ret_dash = (dash$dash.csv.close[nrow(dash)] - dash$dash.csv.close[1])/dash$dash.csv.close[1]

mean_ret_xmr = mean(returns$xmr)
mean_ret_zec = mean(returns$zec)
mean_ret_dash = mean(returns$dash)


anonim_interest = read_csv('anonimity_cryptos_interest.csv')
anonim_interest = data.frame(anonim_interest)
anonim_interest$dash = anonim_interest$dash/100
anonim_interest$zec = anonim_interest$zec/100
anonim_interest$xmr = anonim_interest$xmr/100

mean_int_dash = mean(anonim_interest$dash)
mean_int_zec = mean(anonim_interest$zec)
mean_int_xmr = mean(anonim_interest$xmr)

mean_vol_dash = mean(dash$volatility)
mean_vol_zec = mean(zec$volatility)
mean_vol_xmr = mean(xmr$volatility)

mean_perc_vol_dash = mean_vol_dash / mean(dash$dash.csv.close)
mean_perc_vol_zec = mean_vol_zec / mean(zec$zec.csv.close)
mean_perc_vol_xmr = mean_vol_xmr / mean(xmr$xmr.csv.close)

xmr2 = read_csv('xmr.csv')
nrow(xmr2)
inv_time_xmr = 1 / (nrow(xmr2) / 365)

zec2 = read_csv('zec.csv')
inv_time_zec = 1 / (nrow(zec2) / 365)

dash2 = read_csv('dash.csv')
inv_time_dash = 1 / (nrow(dash2) / 365)


xem2 = read_csv('xem.csv')
tot_perc_ret_xem = (xem$xem.csv.close[nrow(xem)] - xem$xem.csv.close[1]) / xem$xem.csv.close[1]
tot_perc_ret_xem

xrp2 = read_csv('xrp.csv')
tot_perc_ret_xrp = (xrp$xrp.csv.close[nrow(xrp)] - xrp$xrp.csv.close[1] ) / xrp$xrp.csv.close[1]
tot_perc_ret_xrp

tot_perc_ret_neo = (neo$neo.csv.close[nrow(neo)] - neo$neo.csv.close[1]) / neo$neo.csv.close[1]
tot_perc_ret_neo

mean_daily_ret_xem = mean(xem$ret)
mean_daily_ret_xem
mean_daily_ret_xrp = mean(xrp$ret)
mean_daily_ret_xrp
mean_daily_ret_neo = mean(neo$ret)
mean_daily_ret_neo

platform_int = read_csv('platform_interest.csv')
platform_int = data.frame(platform_int)
platform_int$xrp[1:3] = c(0,0,0) #we clean the data to have only numbers. 
platform_int$xem = platform_int$xem/100
platform_int$xrp = as.numeric(platform_int$xrp)
#platform_int = gsub(pattern = '<1', x = platform_int, replacement = 0.5)
platform_int$xrp = platform_int$xrp/100
platform_int$neo = platform_int$neo/100

mean_vol_xem = mean(xem$volatility)
mean_vol_xrp = mean(xrp$volatility)
mean_vol_neo = mean(neo$volatility)
mean_vol_xem
mean_vol_xrp
mean_vol_neo

mean_perc_vol_xem = mean_vol_xem/mean(xem$xem.csv.close)
mean_perc_vol_xrp = mean_vol_xrp/mean(xrp$xrp.csv.close)
mean_perc_vol_neo = mean_vol_neo/mean(neo$neo.csv.close)

inv_time_xem = 1/(nrow(xem2)/365)
inv_time_xrp = 1/(nrow(xrp2)/365)

neo2 = read_csv('neo.csv')
inv_time_neo = 1/(nrow(neo2)/365)


#now let's do the protocol currencies analysis
tot_perc_ret_iota = (iota$iot.csv.close[nrow(iota)] - iota$iot.csv.close[1]) / iota$iot.csv.close[1]
tot_perc_ret_lsk = (lsk$lsk.csv.close[nrow(lsk)] - lsk$lsk.csv.close[1]) / lsk$lsk.csv.close[1]
tot_perc_ret_maid = (maid$maid.csv.close[nrow(maid)] - maid$maid.csv.close[1]) / maid$maid.csv.close[1]

mean_daily_ret_iota = mean(iota$ret)
mean_daily_ret_iota
mean_daily_ret_lsk = mean(lsk$ret)
mean_daily_ret_lsk
mean_daily_ret_maid = mean(maid$ret)
mean_daily_ret_maid


#now let us check the google interest in each of the protocol currencies

protocol_int = read_csv('protocol_interest.csv')

protocol_int$lsk = ifelse(protocol_int$lsk == "<1", 0.5, protocol_int$lsk) #we transform all values <1 to 0.5, as the expected mean between 0 and 1 is supposed to be this if the range behaves normally (bell-shaped).
protocol_int$maid = ifelse(protocol_int$maid == "<1", 0.5, protocol_int$maid)

protocol_int$iota = as.numeric(protocol_int$iota)
protocol_int$lsk = as.numeric(protocol_int$lsk)
protocol_int$maid = as.numeric(protocol_int$maid)

protocol_int$iota = protocol_int$iota/100
protocol_int$lsk = protocol_int$lsk/100
protocol_int$maid = protocol_int$maid / 100

avg_int_iota = mean(protocol_int$iota)
avg_int_lsk = mean(protocol_int$lsk)
avg_int_maid = mean(protocol_int$maid)

mean_vol_iota = mean(iota$volatility)
mean_vol_lsk = mean(lsk$volatility)
mean_vol_maid = mean(maid$volatility)

mean_vol_iota
mean_vol_lsk
mean_vol_maid


perc_vol_iota = mean_vol_iota / mean(iota$iot.csv.close)
perc_vol_lsk = mean_vol_lsk / mean(lsk$lsk.csv.close)
perc_vol_maid = mean_vol_maid / mean(maid$maid.csv.close)

perc_vol_iota
perc_vol_lsk
perc_vol_maid

iota2 = read_csv('iot.csv')
inv_time_iota = 1 / (nrow(iota2) / 365)

lsk2 = read_csv('lsk.csv')
inv_time_lsk = 1 / (nrow(lsk2) / 365)

maid2 = read_csv('maid.csv')
inv_time_maid = 1 / (nrow(maid) / 365)

inv_time_iota
inv_time_lsk
inv_time_maid



